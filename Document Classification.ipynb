{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "dev = pd.read_csv('dev.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "test = pd.read_csv('test.tsv',sep='\\t',header=None,dtype={0:str,1:str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_labels(df):\n",
    "    y = []\n",
    "\n",
    "    for label in df[0]:\n",
    "        label_vec = []\n",
    "\n",
    "        for cat in label:\n",
    "            label_vec.append(int(cat))\n",
    "\n",
    "\n",
    "        y.append(np.array(label_vec))\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(train_file):\n",
    "    train = pd.read_csv(train_file,sep='\\t',header=None,dtype={0:str,1:str})\n",
    "    dev = pd.read_csv('dev.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "    test = pd.read_csv('test.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    train_X = tfidf_vectorizer.fit_transform(train[1])\n",
    "    train_y = vectorize_labels(train)\n",
    "\n",
    "    dev_X = tfidf_vectorizer.transform(dev[1])\n",
    "    dev_y = vectorize_labels(dev)\n",
    "\n",
    "    test_X = tfidf_vectorizer.transform(test[1])\n",
    "    test_y = vectorize_labels(test)\n",
    "\n",
    "    clf = OneVsRestClassifier(SVC(probability=True, kernel='linear'))\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    dev_pred = clf.predict(dev_X)\n",
    "    test_pred = clf.predict(test_X)\n",
    "    \n",
    "    return clf, dev_y, test_y, dev_pred, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, dev_y, test_y, dev_pred, test_pred = train_svm('train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_on_file(clsf, train_file, test_file):\n",
    "    train = pd.read_csv(train_file,sep='\\t',header=None,dtype={0:str,1:str})\n",
    "    dev = pd.read_csv(test_file,sep='\\t',header=None,dtype={0:str,1:str})\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    train_X = tfidf_vectorizer.fit_transform(train[1])\n",
    "    \n",
    "    dev_X = tfidf_vectorizer.transform(dev[1])\n",
    "    dev_y = vectorize_labels(dev)\n",
    "    \n",
    "    dev_pred = clsf.predict(dev_X)\n",
    "\n",
    "    print(metrics.accuracy_score(dev_y, dev_pred),metrics.f1_score(dev_y, dev_pred, average='micro'))\n",
    "    \n",
    "    return dev_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7119305856832971 0.8335969073976454\n"
     ]
    }
   ],
   "source": [
    "dev_pred = eval_model_on_file(clf, 'train.tsv','dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1751   57]\n",
      "  [ 149  348]]\n",
      "\n",
      " [[1541   94]\n",
      "  [ 133  537]]\n",
      "\n",
      " [[1946   35]\n",
      "  [  98  226]]\n",
      "\n",
      " [[2189    6]\n",
      "  [  87   23]]\n",
      "\n",
      " [[1085  117]\n",
      "  [  82 1021]]\n",
      "\n",
      " [[2098   18]\n",
      "  [  53  136]]\n",
      "\n",
      " [[2257    5]\n",
      "  [  25   18]]\n",
      "\n",
      " [[2264    0]\n",
      "  [  35    6]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "print(multilabel_confusion_matrix(dev_y,dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.77       929\n",
      "           1       0.85      0.80      0.82      1401\n",
      "           2       0.85      0.70      0.77       734\n",
      "           3       0.81      0.21      0.34       202\n",
      "           4       0.90      0.90      0.90      2190\n",
      "           5       0.89      0.71      0.79       387\n",
      "           6       0.86      0.46      0.60        79\n",
      "           7       0.91      0.17      0.29        58\n",
      "\n",
      "   micro avg       0.87      0.77      0.82      5980\n",
      "   macro avg       0.87      0.58      0.66      5980\n",
      "weighted avg       0.87      0.77      0.81      5980\n",
      " samples avg       0.83      0.81      0.81      5980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "print(skm.classification_report(test_y,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_X = tfidf_vectorizer.fit_transform(train[1])\n",
    "train_y = vectorize_labels(train)\n",
    "\n",
    "dev_X = tfidf_vectorizer.transform(dev[1])\n",
    "dev_y = vectorize_labels(dev)\n",
    "\n",
    "test_X = tfidf_vectorizer.transform(test[1])\n",
    "test_y = vectorize_labels(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = OneVsRestClassifier(LogisticRegression())\n",
    "lr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6854663774403471, 0.8142493638676844)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pred0 = lr.predict(dev_X)\n",
    "test_pred0 = lr.predict(test_X)\n",
    "print(\"Accuracy:\")\n",
    "metrics.accuracy_score(dev_y, dev_pred0),metrics.f1_score(dev_y, dev_pred0, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1764   44]\n",
      "  [ 169  328]]\n",
      "\n",
      " [[1552   83]\n",
      "  [ 154  516]]\n",
      "\n",
      " [[1946   35]\n",
      "  [ 106  218]]\n",
      "\n",
      " [[2192    3]\n",
      "  [  84   26]]\n",
      "\n",
      " [[1097  105]\n",
      "  [  81 1022]]\n",
      "\n",
      " [[2107    9]\n",
      "  [  77  112]]\n",
      "\n",
      " [[2256    6]\n",
      "  [  29   14]]\n",
      "\n",
      " [[2264    0]\n",
      "  [  37    4]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "print(multilabel_confusion_matrix(dev_y,dev_pred0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75       929\n",
      "           1       0.87      0.77      0.82      1401\n",
      "           2       0.86      0.63      0.73       734\n",
      "           3       0.78      0.24      0.37       202\n",
      "           4       0.92      0.91      0.91      2190\n",
      "           5       0.91      0.63      0.74       387\n",
      "           6       0.81      0.43      0.56        79\n",
      "           7       1.00      0.12      0.22        58\n",
      "\n",
      "   micro avg       0.89      0.75      0.81      5980\n",
      "   macro avg       0.88      0.55      0.64      5980\n",
      "weighted avg       0.89      0.75      0.80      5980\n",
      " samples avg       0.82      0.79      0.79      5980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "print(skm.classification_report(test_y,test_pred0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5262472885032538, 0.654007729793312)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pred2 = dt.predict(dev_X)\n",
    "test_pred2 = dt.predict(test_X)\n",
    "print(\"Accuracy:\")\n",
    "metrics.accuracy_score(dev_y, dev_pred2),metrics.f1_score(dev_y, dev_pred2, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1615  193]\n",
      "  [ 225  272]]\n",
      "\n",
      " [[1405  230]\n",
      "  [ 224  446]]\n",
      "\n",
      " [[1833  148]\n",
      "  [ 144  180]]\n",
      "\n",
      " [[2126   69]\n",
      "  [  77   33]]\n",
      "\n",
      " [[ 938  264]\n",
      "  [ 212  891]]\n",
      "\n",
      " [[2032   84]\n",
      "  [  79  110]]\n",
      "\n",
      " [[2243   19]\n",
      "  [  35    8]]\n",
      "\n",
      " [[2243   21]\n",
      "  [  35    6]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "print(multilabel_confusion_matrix(dev_y,dev_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.53      0.54       929\n",
      "           1       0.66      0.63      0.65      1401\n",
      "           2       0.56      0.54      0.55       734\n",
      "           3       0.32      0.28      0.30       202\n",
      "           4       0.77      0.78      0.78      2190\n",
      "           5       0.55      0.54      0.54       387\n",
      "           6       0.35      0.32      0.33        79\n",
      "           7       0.18      0.22      0.20        58\n",
      "\n",
      "   micro avg       0.65      0.64      0.64      5980\n",
      "   macro avg       0.49      0.48      0.49      5980\n",
      "weighted avg       0.64      0.64      0.64      5980\n",
      " samples avg       0.67      0.67      0.65      5980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "print(skm.classification_report(test_y,test_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5262472885032538, 0.654007729793312)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pred3 = dt.predict(dev_X)\n",
    "test_pred3 = dt.predict(test_X)\n",
    "print(\"Accuracy:\")\n",
    "metrics.accuracy_score(dev_y, dev_pred3),metrics.f1_score(dev_y, dev_pred3, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1615  193]\n",
      "  [ 225  272]]\n",
      "\n",
      " [[1405  230]\n",
      "  [ 224  446]]\n",
      "\n",
      " [[1833  148]\n",
      "  [ 144  180]]\n",
      "\n",
      " [[2126   69]\n",
      "  [  77   33]]\n",
      "\n",
      " [[ 938  264]\n",
      "  [ 212  891]]\n",
      "\n",
      " [[2032   84]\n",
      "  [  79  110]]\n",
      "\n",
      " [[2243   19]\n",
      "  [  35    8]]\n",
      "\n",
      " [[2243   21]\n",
      "  [  35    6]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "print(multilabel_confusion_matrix(dev_y,dev_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.53      0.54       929\n",
      "           1       0.66      0.63      0.65      1401\n",
      "           2       0.56      0.54      0.55       734\n",
      "           3       0.32      0.28      0.30       202\n",
      "           4       0.77      0.78      0.78      2190\n",
      "           5       0.55      0.54      0.54       387\n",
      "           6       0.35      0.32      0.33        79\n",
      "           7       0.18      0.22      0.20        58\n",
      "\n",
      "   micro avg       0.65      0.64      0.64      5980\n",
      "   macro avg       0.49      0.48      0.49      5980\n",
      "weighted avg       0.64      0.64      0.64      5980\n",
      " samples avg       0.67      0.67      0.65      5980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "print(skm.classification_report(test_y,test_pred3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
